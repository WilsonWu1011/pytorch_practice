{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    features,labels = [],[]\n",
    "    fd = open(filename,'r')\n",
    "    for lines in fd.readlines():\n",
    "        feature,label = [],[]\n",
    "        line = lines.strip().split('\\t')\n",
    "        feature.append(1.0)\n",
    "        for idx in range(len(line) - 1):\n",
    "            feature.append(float(line[idx]))\n",
    "        labels.append(float(line[-1]))\n",
    "        \n",
    "        features.append(feature)\n",
    "        #labels.append(label)\n",
    "    fd.close()\n",
    "    \n",
    "    return np.array(features,dtype = np.float32),np.array(labels,dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,labels = load_data(\"./data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,features,labels):\n",
    "        super(CustomDataset,self).__init__()\n",
    "        self.features = torch.from_numpy(features)\n",
    "        self.labels = torch.from_numpy(labels)\n",
    "        #self.labels.shape = (len)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.features[index],self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature , label = custom_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 4.4593, 8.2254])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = custom_dataset,batch_size = 25,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "output_size = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(input_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/60] , Step[4/8] , Loss:0.5763\n",
      "Epoch[1/60] , Step[8/8] , Loss:0.5749\n",
      "Epoch[2/60] , Step[4/8] , Loss:0.6019\n",
      "Epoch[2/60] , Step[8/8] , Loss:0.5924\n",
      "Epoch[3/60] , Step[4/8] , Loss:0.5458\n",
      "Epoch[3/60] , Step[8/8] , Loss:0.5769\n",
      "Epoch[4/60] , Step[4/8] , Loss:0.5182\n",
      "Epoch[4/60] , Step[8/8] , Loss:0.5947\n",
      "Epoch[5/60] , Step[4/8] , Loss:0.5596\n",
      "Epoch[5/60] , Step[8/8] , Loss:0.5584\n",
      "Epoch[6/60] , Step[4/8] , Loss:0.5288\n",
      "Epoch[6/60] , Step[8/8] , Loss:0.4824\n",
      "Epoch[7/60] , Step[4/8] , Loss:0.5058\n",
      "Epoch[7/60] , Step[8/8] , Loss:0.5001\n",
      "Epoch[8/60] , Step[4/8] , Loss:0.4544\n",
      "Epoch[8/60] , Step[8/8] , Loss:0.5184\n",
      "Epoch[9/60] , Step[4/8] , Loss:0.4623\n",
      "Epoch[9/60] , Step[8/8] , Loss:0.4424\n",
      "Epoch[10/60] , Step[4/8] , Loss:0.4533\n",
      "Epoch[10/60] , Step[8/8] , Loss:0.4492\n",
      "Epoch[11/60] , Step[4/8] , Loss:0.5065\n",
      "Epoch[11/60] , Step[8/8] , Loss:0.4480\n",
      "Epoch[12/60] , Step[4/8] , Loss:0.4516\n",
      "Epoch[12/60] , Step[8/8] , Loss:0.4520\n",
      "Epoch[13/60] , Step[4/8] , Loss:0.4343\n",
      "Epoch[13/60] , Step[8/8] , Loss:0.4163\n",
      "Epoch[14/60] , Step[4/8] , Loss:0.4562\n",
      "Epoch[14/60] , Step[8/8] , Loss:0.4455\n",
      "Epoch[15/60] , Step[4/8] , Loss:0.3969\n",
      "Epoch[15/60] , Step[8/8] , Loss:0.3922\n",
      "Epoch[16/60] , Step[4/8] , Loss:0.3464\n",
      "Epoch[16/60] , Step[8/8] , Loss:0.4272\n",
      "Epoch[17/60] , Step[4/8] , Loss:0.4008\n",
      "Epoch[17/60] , Step[8/8] , Loss:0.3774\n",
      "Epoch[18/60] , Step[4/8] , Loss:0.4537\n",
      "Epoch[18/60] , Step[8/8] , Loss:0.4091\n",
      "Epoch[19/60] , Step[4/8] , Loss:0.3623\n",
      "Epoch[19/60] , Step[8/8] , Loss:0.4032\n",
      "Epoch[20/60] , Step[4/8] , Loss:0.4431\n",
      "Epoch[20/60] , Step[8/8] , Loss:0.3558\n",
      "Epoch[21/60] , Step[4/8] , Loss:0.4144\n",
      "Epoch[21/60] , Step[8/8] , Loss:0.3511\n",
      "Epoch[22/60] , Step[4/8] , Loss:0.3554\n",
      "Epoch[22/60] , Step[8/8] , Loss:0.3543\n",
      "Epoch[23/60] , Step[4/8] , Loss:0.3723\n",
      "Epoch[23/60] , Step[8/8] , Loss:0.3830\n",
      "Epoch[24/60] , Step[4/8] , Loss:0.3644\n",
      "Epoch[24/60] , Step[8/8] , Loss:0.3397\n",
      "Epoch[25/60] , Step[4/8] , Loss:0.2995\n",
      "Epoch[25/60] , Step[8/8] , Loss:0.3560\n",
      "Epoch[26/60] , Step[4/8] , Loss:0.3338\n",
      "Epoch[26/60] , Step[8/8] , Loss:0.3183\n",
      "Epoch[27/60] , Step[4/8] , Loss:0.3219\n",
      "Epoch[27/60] , Step[8/8] , Loss:0.3200\n",
      "Epoch[28/60] , Step[4/8] , Loss:0.3351\n",
      "Epoch[28/60] , Step[8/8] , Loss:0.3075\n",
      "Epoch[29/60] , Step[4/8] , Loss:0.3796\n",
      "Epoch[29/60] , Step[8/8] , Loss:0.3094\n",
      "Epoch[30/60] , Step[4/8] , Loss:0.3323\n",
      "Epoch[30/60] , Step[8/8] , Loss:0.3587\n",
      "Epoch[31/60] , Step[4/8] , Loss:0.3233\n",
      "Epoch[31/60] , Step[8/8] , Loss:0.3008\n",
      "Epoch[32/60] , Step[4/8] , Loss:0.3460\n",
      "Epoch[32/60] , Step[8/8] , Loss:0.3073\n",
      "Epoch[33/60] , Step[4/8] , Loss:0.2854\n",
      "Epoch[33/60] , Step[8/8] , Loss:0.3172\n",
      "Epoch[34/60] , Step[4/8] , Loss:0.2751\n",
      "Epoch[34/60] , Step[8/8] , Loss:0.2983\n",
      "Epoch[35/60] , Step[4/8] , Loss:0.3205\n",
      "Epoch[35/60] , Step[8/8] , Loss:0.3107\n",
      "Epoch[36/60] , Step[4/8] , Loss:0.2784\n",
      "Epoch[36/60] , Step[8/8] , Loss:0.2465\n",
      "Epoch[37/60] , Step[4/8] , Loss:0.3136\n",
      "Epoch[37/60] , Step[8/8] , Loss:0.3066\n",
      "Epoch[38/60] , Step[4/8] , Loss:0.2536\n",
      "Epoch[38/60] , Step[8/8] , Loss:0.2977\n",
      "Epoch[39/60] , Step[4/8] , Loss:0.2930\n",
      "Epoch[39/60] , Step[8/8] , Loss:0.2958\n",
      "Epoch[40/60] , Step[4/8] , Loss:0.2760\n",
      "Epoch[40/60] , Step[8/8] , Loss:0.2971\n",
      "Epoch[41/60] , Step[4/8] , Loss:0.2778\n",
      "Epoch[41/60] , Step[8/8] , Loss:0.2682\n",
      "Epoch[42/60] , Step[4/8] , Loss:0.2970\n",
      "Epoch[42/60] , Step[8/8] , Loss:0.2536\n",
      "Epoch[43/60] , Step[4/8] , Loss:0.3093\n",
      "Epoch[43/60] , Step[8/8] , Loss:0.3230\n",
      "Epoch[44/60] , Step[4/8] , Loss:0.3083\n",
      "Epoch[44/60] , Step[8/8] , Loss:0.2785\n",
      "Epoch[45/60] , Step[4/8] , Loss:0.2909\n",
      "Epoch[45/60] , Step[8/8] , Loss:0.2825\n",
      "Epoch[46/60] , Step[4/8] , Loss:0.2355\n",
      "Epoch[46/60] , Step[8/8] , Loss:0.3213\n",
      "Epoch[47/60] , Step[4/8] , Loss:0.2910\n",
      "Epoch[47/60] , Step[8/8] , Loss:0.2540\n",
      "Epoch[48/60] , Step[4/8] , Loss:0.1974\n",
      "Epoch[48/60] , Step[8/8] , Loss:0.2519\n",
      "Epoch[49/60] , Step[4/8] , Loss:0.2704\n",
      "Epoch[49/60] , Step[8/8] , Loss:0.2575\n",
      "Epoch[50/60] , Step[4/8] , Loss:0.2576\n",
      "Epoch[50/60] , Step[8/8] , Loss:0.2606\n",
      "Epoch[51/60] , Step[4/8] , Loss:0.2384\n",
      "Epoch[51/60] , Step[8/8] , Loss:0.2967\n",
      "Epoch[52/60] , Step[4/8] , Loss:0.2317\n",
      "Epoch[52/60] , Step[8/8] , Loss:0.2673\n",
      "Epoch[53/60] , Step[4/8] , Loss:0.2165\n",
      "Epoch[53/60] , Step[8/8] , Loss:0.2944\n",
      "Epoch[54/60] , Step[4/8] , Loss:0.2441\n",
      "Epoch[54/60] , Step[8/8] , Loss:0.2662\n",
      "Epoch[55/60] , Step[4/8] , Loss:0.2410\n",
      "Epoch[55/60] , Step[8/8] , Loss:0.2232\n",
      "Epoch[56/60] , Step[4/8] , Loss:0.2394\n",
      "Epoch[56/60] , Step[8/8] , Loss:0.2539\n",
      "Epoch[57/60] , Step[4/8] , Loss:0.2285\n",
      "Epoch[57/60] , Step[8/8] , Loss:0.2774\n",
      "Epoch[58/60] , Step[4/8] , Loss:0.2379\n",
      "Epoch[58/60] , Step[8/8] , Loss:0.2590\n",
      "Epoch[59/60] , Step[4/8] , Loss:0.2309\n",
      "Epoch[59/60] , Step[8/8] , Loss:0.2374\n",
      "Epoch[60/60] , Step[4/8] , Loss:0.2357\n",
      "Epoch[60/60] , Step[8/8] , Loss:0.2361\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(inputs,targets) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 4 == 0:\n",
    "            print(\"Epoch[{}/{}] , Step[{}/{}] , Loss:{:.4f}\".format(epoch+1,num_epochs,i+1,total_step,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
